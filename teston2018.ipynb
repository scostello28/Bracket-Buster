{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "games = pd.read_pickle('game_data/games_four_years.pkl')\n",
    "g2018 = pd.read_pickle('game_data/games_2018.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# g2018.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Shuffle DataFrames'''\n",
    "games = games.sample(frac=1).reset_index(drop=True)\n",
    "g2018 = g2018.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy_train = games[['W', 'Wp', 'ppg', 'pApg', 'FGp', '3Pp', 'FTp', 'ORBpg', 'RBpg', \n",
    "            'ASTpg', 'STLpg', 'BLKpg', 'TOpg', 'PFpg', 'sos', 'OPppg', \n",
    "            'OPpApg', 'OPFGp', 'OP3Pp', 'OPFTp', 'OPORBpg', 'OPRBpg', \n",
    "            'OPASTpg', 'OPSTLpg', 'OPBLKpg', 'OPTOpg', 'OPPFpg', 'OPsos']]\n",
    "\n",
    "Xy_test = g2018[['W', 'Wp', 'ppg', 'pApg', 'FGp', '3Pp', 'FTp', 'ORBpg', 'RBpg', \n",
    "            'ASTpg', 'STLpg', 'BLKpg', 'TOpg', 'PFpg', 'sos', 'OPppg', \n",
    "            'OPpApg', 'OPFGp', 'OP3Pp', 'OPFTp', 'OPORBpg', 'OPRBpg', \n",
    "            'OPASTpg', 'OPSTLpg', 'OPBLKpg', 'OPTOpg', 'OPPFpg', 'OPsos']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    616\n",
       "1    587\n",
       "Name: W, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xy_test['W'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up features and targets\n",
    "X_train = Xy_train.iloc[:, 1:].as_matrix()\n",
    "y_train = Xy_train.iloc[:, 0].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up features and targets\n",
    "X_test = Xy_test.iloc[:, 1:].as_matrix()\n",
    "y_test = Xy_test.iloc[:, 0].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Standardize Data'''\n",
    "scale = StandardScaler()\n",
    "scale.fit(X_train)\n",
    "X_train = scale.transform(X_train)\n",
    "X_test = scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Fit model on training data'''\n",
    "lg = LogisticRegression()\n",
    "lg.fit(X_train, y_train)\n",
    "lg_predict = lg.predict(X_test)\n",
    "lg_predict_proba = lg.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'ovr',\n",
       " 'n_jobs': 1,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'liblinear',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.77482879,  0.22517121],\n",
       "       [ 0.76544544,  0.23455456],\n",
       "       [ 0.54638219,  0.45361781],\n",
       "       ..., \n",
       "       [ 0.3049869 ,  0.6950131 ],\n",
       "       [ 0.9964017 ,  0.0035983 ],\n",
       "       [ 0.93803814,  0.06196186]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_predict_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = lg_predict_proba[:, [0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78 (% predicted correctly)\n",
      "Precision: 0.78 (predicted positives % correct)\n",
      "Recall: 0.77 (% of positives predicted correctly)\n",
      "f1 Score: 0.78 (weighted average of Precision and Recall)\n"
     ]
    }
   ],
   "source": [
    "lg_accuracy = metrics.accuracy_score(y_test, lg_predict)\n",
    "lg_precision = metrics.precision_score(y_test, lg_predict)\n",
    "lg_recall = metrics.recall_score(y_test, lg_predict)\n",
    "lg_f1 = metrics.f1_score(y_test, lg_predict)\n",
    "print('Accuracy: {:.2f} (% predicted correctly)'.format(lg_accuracy))\n",
    "print('Precision: {:.2f} (predicted positives % correct)'.format(lg_precision))\n",
    "print('Recall: {:.2f} (% of positives predicted correctly)'.format(lg_recall))\n",
    "print('f1 Score: {:.2f} (weighted average of Precision and Recall)'.format(lg_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.        ,  0.00162338,  0.10876623,  0.10876623,  0.13149351,\n",
       "         0.13149351,  0.18993506,  0.18993506,  0.20616883,  0.20616883,\n",
       "         0.21590909,  0.21590909,  0.21753247,  0.21753247,  0.24350649,\n",
       "         0.24350649,  0.26623377,  0.26623377,  0.27597403,  0.27597403,\n",
       "         0.28896104,  0.28896104,  0.29707792,  0.29707792,  0.31331169,\n",
       "         0.31331169,  0.32954545,  0.32954545,  0.34253247,  0.34253247,\n",
       "         0.36038961,  0.36038961,  0.36363636,  0.36363636,  0.36850649,\n",
       "         0.36850649,  0.37337662,  0.37337662,  0.38311688,  0.38311688,\n",
       "         0.3961039 ,  0.3961039 ,  0.40746753,  0.40746753,  0.41720779,\n",
       "         0.41720779,  0.42207792,  0.42207792,  0.42532468,  0.42532468,\n",
       "         0.42694805,  0.42694805,  0.43993506,  0.43993506,  0.44480519,\n",
       "         0.44480519,  0.46428571,  0.46428571,  0.47564935,  0.47564935,\n",
       "         0.47727273,  0.47727273,  0.48376623,  0.48376623,  0.48701299,\n",
       "         0.48701299,  0.49188312,  0.49188312,  0.49512987,  0.49512987,\n",
       "         0.49837662,  0.49837662,  0.50487013,  0.50487013,  0.50974026,\n",
       "         0.50974026,  0.51298701,  0.51298701,  0.51948052,  0.51948052,\n",
       "         0.5275974 ,  0.5275974 ,  0.53571429,  0.53571429,  0.54383117,\n",
       "         0.54383117,  0.54707792,  0.54707792,  0.56006494,  0.56006494,\n",
       "         0.56493506,  0.56493506,  0.56818182,  0.56818182,  0.57142857,\n",
       "         0.57142857,  0.57467532,  0.57467532,  0.57954545,  0.57954545,\n",
       "         0.58441558,  0.58441558,  0.59253247,  0.59253247,  0.59902597,\n",
       "         0.59902597,  0.60064935,  0.60064935,  0.60876623,  0.60876623,\n",
       "         0.61038961,  0.61038961,  0.61363636,  0.61363636,  0.62824675,\n",
       "         0.62824675,  0.63149351,  0.63149351,  0.64285714,  0.64285714,\n",
       "         0.66396104,  0.66396104,  0.66720779,  0.66720779,  0.67207792,\n",
       "         0.67207792,  0.6737013 ,  0.6737013 ,  0.67857143,  0.67857143,\n",
       "         0.68019481,  0.68019481,  0.68506494,  0.68506494,  0.68831169,\n",
       "         0.68831169,  0.69805195,  0.69805195,  0.69967532,  0.69967532,\n",
       "         0.7012987 ,  0.7012987 ,  0.70779221,  0.70779221,  0.71428571,\n",
       "         0.71428571,  0.71753247,  0.71753247,  0.7224026 ,  0.7224026 ,\n",
       "         0.72402597,  0.72402597,  0.72727273,  0.72727273,  0.73376623,\n",
       "         0.73376623,  0.74512987,  0.74512987,  0.74837662,  0.74837662,\n",
       "         0.75487013,  0.75487013,  0.75649351,  0.75649351,  0.75974026,\n",
       "         0.75974026,  0.76136364,  0.76136364,  0.76298701,  0.76298701,\n",
       "         0.76461039,  0.76461039,  0.76623377,  0.76623377,  0.76785714,\n",
       "         0.76785714,  0.76948052,  0.76948052,  0.77272727,  0.77272727,\n",
       "         0.77597403,  0.77597403,  0.7775974 ,  0.7775974 ,  0.77922078,\n",
       "         0.77922078,  0.78246753,  0.78246753,  0.78409091,  0.78409091,\n",
       "         0.78571429,  0.78571429,  0.78896104,  0.78896104,  0.79058442,\n",
       "         0.79058442,  0.79545455,  0.79545455,  0.7987013 ,  0.7987013 ,\n",
       "         0.80194805,  0.80194805,  0.80357143,  0.80357143,  0.80519481,\n",
       "         0.80519481,  0.80681818,  0.80681818,  0.80844156,  0.80844156,\n",
       "         0.81006494,  0.81006494,  0.81168831,  0.81168831,  0.81331169,\n",
       "         0.81331169,  0.81493506,  0.81493506,  0.81655844,  0.81655844,\n",
       "         0.82305195,  0.82305195,  0.82467532,  0.82467532,  0.8262987 ,\n",
       "         0.8262987 ,  0.82954545,  0.82954545,  0.83116883,  0.83116883,\n",
       "         0.83279221,  0.83279221,  0.83441558,  0.83441558,  0.83603896,\n",
       "         0.83603896,  0.84090909,  0.84090909,  0.84902597,  0.84902597,\n",
       "         0.85064935,  0.85064935,  0.85227273,  0.85227273,  0.8538961 ,\n",
       "         0.8538961 ,  0.85551948,  0.85551948,  0.85876623,  0.85876623,\n",
       "         0.86038961,  0.86038961,  0.86363636,  0.86363636,  0.86688312,\n",
       "         0.86688312,  0.86850649,  0.86850649,  0.87175325,  0.87175325,\n",
       "         0.87337662,  0.87337662,  0.875     ,  0.875     ,  0.87662338,\n",
       "         0.87662338,  0.87824675,  0.87824675,  0.87987013,  0.87987013,\n",
       "         0.88311688,  0.88311688,  0.88474026,  0.88474026,  0.88636364,\n",
       "         0.88636364,  0.88961039,  0.88961039,  0.89123377,  0.89123377,\n",
       "         0.89448052,  0.89448052,  0.8961039 ,  0.8961039 ,  0.89772727,\n",
       "         0.89772727,  0.90097403,  0.90097403,  0.9025974 ,  0.9025974 ,\n",
       "         0.90422078,  0.90422078,  0.90584416,  0.90584416,  0.90746753,\n",
       "         0.90746753,  0.90909091,  0.90909091,  0.91233766,  0.91233766,\n",
       "         0.91396104,  0.91396104,  0.91883117,  0.91883117,  0.92045455,\n",
       "         0.92045455,  0.92207792,  0.92207792,  0.9237013 ,  0.9237013 ,\n",
       "         0.92532468,  0.92532468,  0.92694805,  0.92694805,  0.93181818,\n",
       "         0.93181818,  0.93344156,  0.93344156,  0.93506494,  0.93506494,\n",
       "         0.93831169,  0.93831169,  0.93993506,  0.93993506,  0.94155844,\n",
       "         0.94155844,  0.94318182,  0.94318182,  0.94480519,  0.94480519,\n",
       "         0.94642857,  0.94642857,  0.94805195,  0.94805195,  0.94967532,\n",
       "         0.94967532,  0.9512987 ,  0.9512987 ,  0.95454545,  0.95454545,\n",
       "         0.95616883,  0.95616883,  0.95779221,  0.95779221,  0.95941558,\n",
       "         0.95941558,  0.96103896,  0.96103896,  0.96266234,  0.96266234,\n",
       "         0.96428571,  0.96428571,  0.96590909,  0.96590909,  0.96753247,\n",
       "         0.96753247,  0.96915584,  0.96915584,  0.97077922,  0.97077922,\n",
       "         0.9724026 ,  0.9724026 ,  0.97402597,  0.97402597,  0.97564935,\n",
       "         0.97564935,  0.97727273,  0.97727273,  0.98051948,  0.98051948,\n",
       "         0.98214286,  0.98214286,  0.98376623,  0.98376623,  0.98538961,\n",
       "         0.98538961,  0.98701299,  0.98701299,  0.98863636,  0.98863636,\n",
       "         0.99188312,  0.99188312,  0.99350649,  0.99350649,  0.99512987,\n",
       "         0.99512987,  0.99675325,  0.99675325,  0.99837662,  0.99837662,\n",
       "         1.        ,  1.        ]),\n",
       " array([ 0.        ,  0.        ,  0.        ,  0.00170358,  0.00170358,\n",
       "         0.00340716,  0.00340716,  0.00511073,  0.00511073,  0.00681431,\n",
       "         0.00681431,  0.00851789,  0.00851789,  0.01022147,  0.01022147,\n",
       "         0.01192504,  0.01192504,  0.01362862,  0.01362862,  0.0153322 ,\n",
       "         0.0153322 ,  0.01703578,  0.01703578,  0.01873935,  0.01873935,\n",
       "         0.02044293,  0.02044293,  0.02214651,  0.02214651,  0.02385009,\n",
       "         0.02385009,  0.02555366,  0.02555366,  0.02725724,  0.02725724,\n",
       "         0.02896082,  0.02896082,  0.0306644 ,  0.0306644 ,  0.03407155,\n",
       "         0.03407155,  0.03577513,  0.03577513,  0.03747871,  0.03747871,\n",
       "         0.03918228,  0.03918228,  0.04088586,  0.04088586,  0.04258944,\n",
       "         0.04258944,  0.04429302,  0.04429302,  0.04599659,  0.04599659,\n",
       "         0.04770017,  0.04770017,  0.04940375,  0.04940375,  0.05110733,\n",
       "         0.05110733,  0.0528109 ,  0.0528109 ,  0.05451448,  0.05451448,\n",
       "         0.05621806,  0.05621806,  0.05792164,  0.05792164,  0.05962521,\n",
       "         0.05962521,  0.06132879,  0.06132879,  0.06303237,  0.06303237,\n",
       "         0.06473595,  0.06473595,  0.06643952,  0.06643952,  0.0681431 ,\n",
       "         0.0681431 ,  0.06984668,  0.06984668,  0.07155026,  0.07155026,\n",
       "         0.07325383,  0.07325383,  0.07495741,  0.07495741,  0.07666099,\n",
       "         0.07666099,  0.08006814,  0.08006814,  0.08177172,  0.08177172,\n",
       "         0.0834753 ,  0.0834753 ,  0.08517888,  0.08517888,  0.09028961,\n",
       "         0.09028961,  0.09199319,  0.09199319,  0.09369676,  0.09369676,\n",
       "         0.09540034,  0.09540034,  0.09710392,  0.09710392,  0.0988075 ,\n",
       "         0.0988075 ,  0.10051107,  0.10051107,  0.10391823,  0.10391823,\n",
       "         0.10562181,  0.10562181,  0.10902896,  0.10902896,  0.11073254,\n",
       "         0.11073254,  0.11243612,  0.11243612,  0.11413969,  0.11413969,\n",
       "         0.11754685,  0.11754685,  0.11925043,  0.11925043,  0.12265758,\n",
       "         0.12265758,  0.12776831,  0.12776831,  0.13117547,  0.13117547,\n",
       "         0.13287905,  0.13287905,  0.13798978,  0.13798978,  0.13969336,\n",
       "         0.13969336,  0.14480409,  0.14480409,  0.14650767,  0.14650767,\n",
       "         0.1516184 ,  0.1516184 ,  0.15502555,  0.15502555,  0.15672913,\n",
       "         0.15672913,  0.15843271,  0.15843271,  0.16013629,  0.16013629,\n",
       "         0.16354344,  0.16354344,  0.16524702,  0.16524702,  0.1669506 ,\n",
       "         0.1669506 ,  0.16865417,  0.16865417,  0.17035775,  0.17035775,\n",
       "         0.17546848,  0.17546848,  0.17717206,  0.17717206,  0.17887564,\n",
       "         0.17887564,  0.18568995,  0.18568995,  0.19250426,  0.19250426,\n",
       "         0.19420784,  0.19420784,  0.19591141,  0.19591141,  0.19761499,\n",
       "         0.19761499,  0.2044293 ,  0.2044293 ,  0.20954003,  0.20954003,\n",
       "         0.21124361,  0.21124361,  0.22146508,  0.22146508,  0.22316865,\n",
       "         0.22316865,  0.22487223,  0.22487223,  0.22657581,  0.22657581,\n",
       "         0.22998296,  0.22998296,  0.2350937 ,  0.2350937 ,  0.24020443,\n",
       "         0.24020443,  0.25042589,  0.25042589,  0.25383305,  0.25383305,\n",
       "         0.2572402 ,  0.2572402 ,  0.25894378,  0.25894378,  0.26235094,\n",
       "         0.26235094,  0.26405451,  0.26405451,  0.26746167,  0.26746167,\n",
       "         0.26916525,  0.26916525,  0.27086882,  0.27086882,  0.2879046 ,\n",
       "         0.2879046 ,  0.29131175,  0.29131175,  0.29642249,  0.29642249,\n",
       "         0.30153322,  0.30153322,  0.3032368 ,  0.3032368 ,  0.30834753,\n",
       "         0.30834753,  0.31345826,  0.31345826,  0.31686542,  0.31686542,\n",
       "         0.31856899,  0.31856899,  0.32367973,  0.32367973,  0.3253833 ,\n",
       "         0.3253833 ,  0.32708688,  0.32708688,  0.32879046,  0.32879046,\n",
       "         0.33049404,  0.33049404,  0.33390119,  0.33390119,  0.33560477,\n",
       "         0.33560477,  0.33730835,  0.33730835,  0.34241908,  0.34241908,\n",
       "         0.34923339,  0.34923339,  0.35945486,  0.35945486,  0.36286201,\n",
       "         0.36286201,  0.3713799 ,  0.3713799 ,  0.37649063,  0.37649063,\n",
       "         0.37819421,  0.37819421,  0.37989779,  0.37989779,  0.38841567,\n",
       "         0.38841567,  0.39182283,  0.39182283,  0.39863714,  0.39863714,\n",
       "         0.40034072,  0.40034072,  0.41567291,  0.41567291,  0.42589438,\n",
       "         0.42589438,  0.439523  ,  0.439523  ,  0.44293015,  0.44293015,\n",
       "         0.44463373,  0.44463373,  0.44804089,  0.44804089,  0.4548552 ,\n",
       "         0.4548552 ,  0.45826235,  0.45826235,  0.46166951,  0.46166951,\n",
       "         0.47018739,  0.47018739,  0.47529813,  0.47529813,  0.4770017 ,\n",
       "         0.4770017 ,  0.48892675,  0.48892675,  0.4923339 ,  0.4923339 ,\n",
       "         0.49574106,  0.49574106,  0.50255537,  0.50255537,  0.51107325,\n",
       "         0.51107325,  0.51618399,  0.51618399,  0.51788756,  0.51788756,\n",
       "         0.51959114,  0.51959114,  0.52129472,  0.52129472,  0.52981261,\n",
       "         0.52981261,  0.54003407,  0.54003407,  0.54684838,  0.54684838,\n",
       "         0.55195911,  0.55195911,  0.55706985,  0.55706985,  0.55877342,\n",
       "         0.55877342,  0.560477  ,  0.560477  ,  0.56899489,  0.56899489,\n",
       "         0.58091993,  0.58091993,  0.5911414 ,  0.5911414 ,  0.59795571,\n",
       "         0.59795571,  0.6132879 ,  0.6132879 ,  0.62010221,  0.62010221,\n",
       "         0.62350937,  0.62350937,  0.63032368,  0.63032368,  0.63202726,\n",
       "         0.63202726,  0.63884157,  0.63884157,  0.66269165,  0.66269165,\n",
       "         0.67632027,  0.67632027,  0.67802385,  0.67802385,  0.67972743,\n",
       "         0.67972743,  0.68654174,  0.68654174,  0.6967632 ,  0.6967632 ,\n",
       "         0.70187394,  0.70187394,  0.70357751,  0.70357751,  0.72231687,\n",
       "         0.72231687,  0.7274276 ,  0.7274276 ,  0.74105622,  0.74105622,\n",
       "         0.7427598 ,  0.7427598 ,  0.80068143,  0.80068143,  0.80408859,\n",
       "         0.80408859,  0.80749574,  0.80749574,  0.81260647,  0.81260647,\n",
       "         0.84667802,  0.84667802,  0.86201022,  0.86201022,  0.95570698,\n",
       "         0.95570698,  1.        ]),\n",
       " array([  1.99961837e+00,   9.99618372e-01,   9.64681679e-01,\n",
       "          9.64435868e-01,   9.56467361e-01,   9.56145311e-01,\n",
       "          9.35897932e-01,   9.35740033e-01,   9.29409550e-01,\n",
       "          9.27961900e-01,   9.24599139e-01,   9.24374804e-01,\n",
       "          9.23422122e-01,   9.23238254e-01,   9.15646927e-01,\n",
       "          9.15202167e-01,   9.03899862e-01,   9.03677752e-01,\n",
       "          9.00140925e-01,   8.99593034e-01,   8.95453597e-01,\n",
       "          8.95349987e-01,   8.94207913e-01,   8.93295660e-01,\n",
       "          8.84868681e-01,   8.84542436e-01,   8.75792852e-01,\n",
       "          8.75445381e-01,   8.72425975e-01,   8.69179767e-01,\n",
       "          8.62724432e-01,   8.61092168e-01,   8.58920915e-01,\n",
       "          8.58761842e-01,   8.58110863e-01,   8.56843203e-01,\n",
       "          8.54308639e-01,   8.53941141e-01,   8.51442998e-01,\n",
       "          8.49304546e-01,   8.39247319e-01,   8.39017760e-01,\n",
       "          8.34582536e-01,   8.33917083e-01,   8.30424841e-01,\n",
       "          8.30135585e-01,   8.29516312e-01,   8.29340017e-01,\n",
       "          8.25648790e-01,   8.24869178e-01,   8.24116650e-01,\n",
       "          8.23570273e-01,   8.17422738e-01,   8.16733649e-01,\n",
       "          8.16073291e-01,   8.12825404e-01,   8.07061930e-01,\n",
       "          8.06147170e-01,   8.00293356e-01,   7.99487063e-01,\n",
       "          7.99209935e-01,   7.98664693e-01,   7.96025608e-01,\n",
       "          7.95091759e-01,   7.93986250e-01,   7.93402272e-01,\n",
       "          7.91252260e-01,   7.89359099e-01,   7.88942043e-01,\n",
       "          7.87635903e-01,   7.85909260e-01,   7.85641233e-01,\n",
       "          7.81820591e-01,   7.81376141e-01,   7.80117883e-01,\n",
       "          7.79451587e-01,   7.78474562e-01,   7.77976386e-01,\n",
       "          7.76302155e-01,   7.75103294e-01,   7.71287607e-01,\n",
       "          7.71117410e-01,   7.66509222e-01,   7.66112697e-01,\n",
       "          7.62037355e-01,   7.61705306e-01,   7.59722435e-01,\n",
       "          7.59699369e-01,   7.49596221e-01,   7.48894643e-01,\n",
       "          7.46184600e-01,   7.43605176e-01,   7.42469749e-01,\n",
       "          7.41643872e-01,   7.39584203e-01,   7.38668654e-01,\n",
       "          7.36901865e-01,   7.36646498e-01,   7.32676232e-01,\n",
       "          7.29732458e-01,   7.26707955e-01,   7.26314466e-01,\n",
       "          7.21401449e-01,   7.20776536e-01,   7.18586857e-01,\n",
       "          7.18403692e-01,   7.18061369e-01,   7.17430494e-01,\n",
       "          7.05062818e-01,   7.04699545e-01,   7.04313244e-01,\n",
       "          7.00013475e-01,   6.97436774e-01,   6.95010092e-01,\n",
       "          6.88899028e-01,   6.88434806e-01,   6.86531128e-01,\n",
       "          6.84258864e-01,   6.78072494e-01,   6.75588951e-01,\n",
       "          6.64857508e-01,   6.64304101e-01,   6.56916570e-01,\n",
       "          6.55671225e-01,   6.53317102e-01,   6.53030034e-01,\n",
       "          6.52776019e-01,   6.52294541e-01,   6.49076690e-01,\n",
       "          6.46168321e-01,   6.46123265e-01,   6.41857376e-01,\n",
       "          6.39871869e-01,   6.37711230e-01,   6.36004652e-01,\n",
       "          6.34513156e-01,   6.26161892e-01,   6.20327508e-01,\n",
       "          6.18943626e-01,   6.18306731e-01,   6.17406595e-01,\n",
       "          6.12878958e-01,   6.11256579e-01,   6.08987731e-01,\n",
       "          6.00815270e-01,   5.98437458e-01,   5.97220697e-01,\n",
       "          5.93227863e-01,   5.87782495e-01,   5.87408915e-01,\n",
       "          5.84468033e-01,   5.81924144e-01,   5.80877410e-01,\n",
       "          5.79382761e-01,   5.74781015e-01,   5.69264023e-01,\n",
       "          5.66653671e-01,   5.66571960e-01,   5.64791240e-01,\n",
       "          5.64365153e-01,   5.57477763e-01,   5.56930256e-01,\n",
       "          5.56908108e-01,   5.54845566e-01,   5.52801958e-01,\n",
       "          5.51875506e-01,   5.50756954e-01,   5.46382190e-01,\n",
       "          5.45793682e-01,   5.45487614e-01,   5.45287758e-01,\n",
       "          5.37377401e-01,   5.35127763e-01,   5.31062885e-01,\n",
       "          5.30743641e-01,   5.30634368e-01,   5.27551133e-01,\n",
       "          5.27536667e-01,   5.26634868e-01,   5.26394505e-01,\n",
       "          5.26091343e-01,   5.22466942e-01,   5.22363685e-01,\n",
       "          5.20365141e-01,   5.20283918e-01,   5.18195659e-01,\n",
       "          5.16426401e-01,   5.09956971e-01,   5.09889536e-01,\n",
       "          5.09219361e-01,   5.08822096e-01,   5.08799440e-01,\n",
       "          5.07965232e-01,   5.07478445e-01,   5.05743901e-01,\n",
       "          4.99988031e-01,   4.98048545e-01,   4.93488681e-01,\n",
       "          4.89940361e-01,   4.79255631e-01,   4.78938786e-01,\n",
       "          4.71710494e-01,   4.70791870e-01,   4.69411797e-01,\n",
       "          4.68326688e-01,   4.65473019e-01,   4.65194483e-01,\n",
       "          4.63468574e-01,   4.61046362e-01,   4.59007077e-01,\n",
       "          4.57662795e-01,   4.57042834e-01,   4.56961977e-01,\n",
       "          4.52536324e-01,   4.51669944e-01,   4.51120532e-01,\n",
       "          4.49384804e-01,   4.47102204e-01,   4.45628344e-01,\n",
       "          4.36013521e-01,   4.29722301e-01,   4.29104867e-01,\n",
       "          4.28676764e-01,   4.23282281e-01,   4.22853950e-01,\n",
       "          4.19977247e-01,   4.19413283e-01,   4.19164803e-01,\n",
       "          4.18127840e-01,   4.16382235e-01,   4.12107535e-01,\n",
       "          4.10696159e-01,   4.09129062e-01,   4.04077386e-01,\n",
       "          4.03647664e-01,   4.02227119e-01,   3.98176918e-01,\n",
       "          3.95582454e-01,   3.91857835e-01,   3.91537208e-01,\n",
       "          3.89577695e-01,   3.87423116e-01,   3.87121201e-01,\n",
       "          3.86867695e-01,   3.85441506e-01,   3.84451864e-01,\n",
       "          3.83420027e-01,   3.82283033e-01,   3.79364797e-01,\n",
       "          3.77833183e-01,   3.77522114e-01,   3.75277758e-01,\n",
       "          3.72917351e-01,   3.68104273e-01,   3.67633197e-01,\n",
       "          3.64504744e-01,   3.63226877e-01,   3.58439742e-01,\n",
       "          3.56825198e-01,   3.56022333e-01,   3.55645148e-01,\n",
       "          3.50965872e-01,   3.50193287e-01,   3.48764365e-01,\n",
       "          3.47072846e-01,   3.46308270e-01,   3.45940436e-01,\n",
       "          3.45418605e-01,   3.41422968e-01,   3.36115937e-01,\n",
       "          3.33318913e-01,   3.32623498e-01,   3.32424512e-01,\n",
       "          3.29139716e-01,   3.27771795e-01,   3.25393134e-01,\n",
       "          3.22260901e-01,   3.14351739e-01,   3.12784095e-01,\n",
       "          3.08251725e-01,   3.06018190e-01,   3.02231933e-01,\n",
       "          2.99545402e-01,   2.97543839e-01,   2.97047410e-01,\n",
       "          2.95495263e-01,   2.94032363e-01,   2.92534180e-01,\n",
       "          2.92411735e-01,   2.88914431e-01,   2.85462049e-01,\n",
       "          2.83512659e-01,   2.83452724e-01,   2.77616672e-01,\n",
       "          2.77210004e-01,   2.69734182e-01,   2.69252658e-01,\n",
       "          2.67535297e-01,   2.66389923e-01,   2.65581158e-01,\n",
       "          2.65209930e-01,   2.56977906e-01,   2.51126865e-01,\n",
       "          2.48711947e-01,   2.47811621e-01,   2.43062012e-01,\n",
       "          2.40958770e-01,   2.37871235e-01,   2.36223601e-01,\n",
       "          2.31966687e-01,   2.31797621e-01,   2.28701328e-01,\n",
       "          2.27150994e-01,   2.27088165e-01,   2.25497877e-01,\n",
       "          2.25452746e-01,   2.22739160e-01,   2.22213008e-01,\n",
       "          2.21436182e-01,   2.18684509e-01,   2.18253860e-01,\n",
       "          2.07309042e-01,   2.07173739e-01,   2.04697165e-01,\n",
       "          2.04312238e-01,   2.02175228e-01,   2.02175217e-01,\n",
       "          2.00686136e-01,   2.00333861e-01,   1.99764611e-01,\n",
       "          1.99711107e-01,   1.99262674e-01,   1.97994890e-01,\n",
       "          1.94251584e-01,   1.93700453e-01,   1.89445495e-01,\n",
       "          1.88345358e-01,   1.83997972e-01,   1.82651350e-01,\n",
       "          1.78063377e-01,   1.77888050e-01,   1.71603629e-01,\n",
       "          1.70673664e-01,   1.67779609e-01,   1.66155516e-01,\n",
       "          1.64726284e-01,   1.64355217e-01,   1.58507136e-01,\n",
       "          1.56689768e-01,   1.56671988e-01,   1.56603941e-01,\n",
       "          1.52106445e-01,   1.51915020e-01,   1.43834278e-01,\n",
       "          1.43374778e-01,   1.37076061e-01,   1.36511536e-01,\n",
       "          1.35824595e-01,   1.35760388e-01,   1.35546393e-01,\n",
       "          1.35393087e-01,   1.31735620e-01,   1.31164541e-01,\n",
       "          1.25690741e-01,   1.24967058e-01,   1.21144560e-01,\n",
       "          1.21107505e-01,   1.20183262e-01,   1.18369293e-01,\n",
       "          1.12798986e-01,   1.12469774e-01,   1.11671985e-01,\n",
       "          1.10571276e-01,   1.06681126e-01,   1.06414539e-01,\n",
       "          1.05452410e-01,   1.05207111e-01,   8.31875810e-02,\n",
       "          8.22558609e-02,   8.10567156e-02,   7.93740125e-02,\n",
       "          7.87949172e-02,   7.84055352e-02,   7.71157155e-02,\n",
       "          7.57217710e-02,   6.09109410e-02,   6.06295285e-02,\n",
       "          5.31964426e-02,   5.17895772e-02,   1.67767504e-02,\n",
       "          1.63872408e-02,   1.00620035e-03]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_curve(y_test, y_score, pos_label=None, sample_weight=None, drop_intermediate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13960762406247926"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y_test, y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3664"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(y_train)[np.isnan(y_train) == False].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_val_logistic(X, y, model, n_folds=5, random_seed=154):\n",
    "    \"\"\"Estimate the in- and out-of-sample error of a model using cross\n",
    "    validation.\n",
    " \n",
    "    Parameters\n",
    "    ----------\n",
    " \n",
    "    X: np.array\n",
    "      Matrix of predictors, standardized\n",
    " \n",
    "    y: np.array\n",
    "      Target array, standardized\n",
    " \n",
    "    model: sklearn model object.\n",
    "      The estimator to fit.  Must have fit and predict methods.\n",
    " \n",
    "    n_folds: int\n",
    "      The number of folds in the cross validation.\n",
    " \n",
    "    random_seed: int\n",
    "      A seed for the random number generator, for repeatability.\n",
    " \n",
    "    Returns\n",
    "    -------\n",
    "    mean accuracy across folds\n",
    "    \"\"\"\n",
    "    kf = KFold(n_folds)\n",
    "    accuracy_list = []\n",
    "    cfs = []\n",
    "    for train_index,test_index in kf.split(X):\n",
    "        # define variables\n",
    "        X_train = X[train_index]\n",
    "        y_train = y[train_index]\n",
    "        X_test = X[test_index]\n",
    "        y_test = y[test_index]\n",
    "        print(y_test)\n",
    "        # fit model\n",
    "#         model.fit(X_train, y_train)\n",
    "#         y_hat_train = model.predict(X_train)\n",
    "#         y_hat_test = model.predict(X_test) \n",
    "#         # evaluate model\n",
    "#         accuracy_test = metrics.accuracy_score(y_test, y_hat_test)\n",
    "#         errorlist.append(accuracy_test)\n",
    "#         # store coefficients\n",
    "#         cfs.append (model.coef_)\n",
    "#     # select best coefficients \n",
    "#     accuracies = np.asarray(accuracy_list)\n",
    "#     idx_max_test_accuracy = accuracies.argmax()   \n",
    "#     cfs_best = cfs[idx_min_test_accuracy]\n",
    "    \n",
    "#     return(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.786570862186\n"
     ]
    }
   ],
   "source": [
    "logcv = LogisticRegression()\n",
    "ridgecv = Ridge(alpha=.5)\n",
    "lassocv = Lasso(alpha=.5)\n",
    "enetcv = ElasticNet(alpha=.5)\n",
    "log_cv_acc = cross_validate(logcv, X_train, y_train, scoring='accuracy', cv=5, return_train_score=False)\n",
    "# ridge_cv_acc = cross_validate(ridgecv, X_train, y_train, scoring='accuracy', cv=5, return_train_score=False)\n",
    "# lasso_cv_acc = cross_validate(lassocv, X_train, y_train, scoring='accuracy', cv=5, return_train_score=False)\n",
    "# enet_cv_acc = cross_validate(enetcv, X_train, y_train, scoring='accuracy', cv=5, return_train_score=False)\n",
    "print(log_cv_acc['test_score'].mean())\n",
    "# print(ridge_cv_acc['test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Ridge(alpha=.5)\n",
    "X = X_train\n",
    "y = y_train\n",
    "cv_accuracy = cross_val_logistic(X, y, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
