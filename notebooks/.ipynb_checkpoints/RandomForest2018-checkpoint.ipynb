{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = pd.read_pickle('/Users/sec/galvanize/capstone1/game_data/all_games.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "season2018     1101\n",
       "season2017     1082\n",
       "season2016     1078\n",
       "season2015     1070\n",
       "season2014     1062\n",
       "tourney2014      49\n",
       "tourney2016      47\n",
       "tourney2015      43\n",
       "tourney2017      40\n",
       "tourney2018      23\n",
       "Name: GameType, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games.GameType.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def games_up_to_2018_season_filter(df):\n",
    "    '''Filter for games up to 2018 season'''\n",
    "    notourney2018 = (df['GameType'] != 'tourney2018')\n",
    "    noseason2018 = (df['GameType'] != 'season2018')\n",
    "    games_up_to_2018_season = df[notourney2018 & noseason2018]\n",
    "    return games_up_to_2018_season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def season2018_filter(df):\n",
    "    '''Filter for games up to 2018 season'''\n",
    "    season2018cond = (df['GameType'] == 'season2018')\n",
    "    season2018 = df[season2018cond]\n",
    "    return season2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "season2017     1082\n",
       "season2016     1078\n",
       "season2015     1070\n",
       "season2014     1062\n",
       "tourney2014      49\n",
       "tourney2016      47\n",
       "tourney2015      43\n",
       "tourney2017      40\n",
       "Name: GameType, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games_up_to_2018_season = games_up_to_2018_season_filter(games)\n",
    "games_up_to_2018_season.GameType.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "season2018    1101\n",
       "Name: GameType, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "season2018 = season2018_filter(games)\n",
    "season2018.GameType.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Shuffle DataFrames'''\n",
    "games_up_to_2018_season = games_up_to_2018_season.sample(frac=1).reset_index(drop=True)\n",
    "season2018 = season2018.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy_train = games_up_to_2018_season[['W', 'Wp', 'ppg', 'pApg', 'FGp', '3Pp', 'FTp', 'ORBpg', 'RBpg', \n",
    "            'ASTpg', 'STLpg', 'BLKpg', 'TOpg', 'PFpg', 'sos', 'OPWp', 'OPppg', \n",
    "            'OPpApg', 'OPFGp', 'OP3Pp', 'OPFTp', 'OPORBpg', 'OPRBpg', \n",
    "            'OPASTpg', 'OPSTLpg', 'OPBLKpg', 'OPTOpg', 'OPPFpg', 'OPsos']]\n",
    "\n",
    "Xy_test = season2018[['W', 'Wp', 'ppg', 'pApg', 'FGp', '3Pp', 'FTp', 'ORBpg', 'RBpg', \n",
    "            'ASTpg', 'STLpg', 'BLKpg', 'TOpg', 'PFpg', 'sos', 'OPWp', 'OPppg', \n",
    "            'OPpApg', 'OPFGp', 'OP3Pp', 'OPFTp', 'OPORBpg', 'OPRBpg', \n",
    "            'OPASTpg', 'OPSTLpg', 'OPBLKpg', 'OPTOpg', 'OPPFpg', 'OPsos']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up features and targets\n",
    "X_train = Xy_train.iloc[:, 1:].as_matrix()\n",
    "y_train = Xy_train.iloc[:, 0].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up features and targets\n",
    "X_test = Xy_test.iloc[:, 1:].as_matrix()\n",
    "y_test = Xy_test.iloc[:, 0].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Standardize Data'''\n",
    "scale = StandardScaler()\n",
    "scale.fit(X_train)\n",
    "X_train = scale.transform(X_train)\n",
    "X_test = scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oob: 0.67, test_accuracy: 0.64\n"
     ]
    }
   ],
   "source": [
    "initial_rf = RandomForestClassifier(n_estimators=500, oob_score=True).fit(X_train, y_train)\n",
    "initial_rf_oob_score = initial_rf.oob_score_\n",
    "initial_rf_accuracy = initial_rf.score(X_test, y_test)\n",
    "print('oob: {:.2f}, test_accuracy: {:.2f}'.format(initial_rf_oob_score, initial_rf_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 900}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_n_estimators = list(range(200, 1000, 100))    # default = 10      - Number of trees\n",
    "rf_max_depth = [None]                            # default = None    - Max Depth of tree. None lets tree expand until leaves pure or until min_samples_split\n",
    "rf_min_samples_split = [2]                       # default = 2       - Min number of samples required to split a node\n",
    "rf_min_samples_leaf = [1]                        # default = 1       - Min samples per terminal leaf\n",
    "rf_min_weight_fraction_leaf = [0.0]              # default = 0       - Min weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node.\n",
    "rf_max_features = ['sqrt']                       # default = 'sqrt'  - Number of features to consider when looking for the best splits\n",
    "rf_max_leaf_nodes = [None]                       # default = None\n",
    "rf_min_impurity_decrease = [0.0]                 # default = 0.0\n",
    "rf_min_impurity_split = [None]                   # default = None\n",
    "\n",
    "params = {'n_estimators': rf_n_estimators, \n",
    "          'max_depth': rf_max_depth, \n",
    "          'min_samples_split': rf_min_samples_split,\n",
    "          'min_samples_leaf': rf_min_samples_leaf,\n",
    "          'min_weight_fraction_leaf': rf_min_weight_fraction_leaf,\n",
    "          'max_features': rf_max_features,\n",
    "          'max_leaf_nodes': rf_max_leaf_nodes,\n",
    "          'min_impurity_decrease': rf_min_impurity_decrease,\n",
    "          'min_impurity_split': rf_min_impurity_split}\n",
    "\n",
    "rf = GridSearchCV(RandomForestClassifier(), param_grid=params, scoring='accuracy', n_jobs=-1, cv=5)\n",
    "rf.fit(X_train, y_train)\n",
    "rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6774770744799821"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6385104450499546"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracy: 0.65\n"
     ]
    }
   ],
   "source": [
    "initial_boost = GradientBoostingClassifier().fit(X_train, y_train)\n",
    "initial_boost_accuracy = initial_boost.score(X_test, y_test)\n",
    "print('test_accuracy: {:.2f}'.format(initial_boost_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-19-0dff8634a63f>, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-0dff8634a63f>\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    'min_samples_split' = gdb_min_samples_split,\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "gdb_loss = ['deviance', 'exponential']           # default = 'deviance'\n",
    "gdb_learning_rate = [0.1]                        # default = 0.1\n",
    "gdb_n_estimators = list(range(50, 500, 50))      # default = 100\n",
    "gdb_max_depth = list(range(2, 6, 1))             # default = 3\n",
    "gdb_min_samples_split = list(range(2, 4, 1))     # default = 2\n",
    "gdb_min_samples_leaf = list(range(1, 9, 2))      # default = 1\n",
    "gdb_max_features = ['sqrt']                      # default = 'sqrt'\n",
    "\n",
    "\n",
    "\n",
    "gdb_grid = {'loss': gdb_loss,\n",
    "            'learning_rate': gdb_learning_rate,\n",
    "            'n_estimators': gdb_n_estimators,\n",
    "            'max_depth': gdb_max_depth,\n",
    "            'min_samples_split': gdb_min_samples_split,\n",
    "            'min_samples_leaf': gdb_min_samples_leaf,\n",
    "            'max_features': gdb_max_features}\n",
    "\n",
    "gdb = GridSearchCV(GradientBoostingClassifier(), param_grid=gdb_grid, scoring='accuracy', n_jobs=-1, cv=5, verbose=1)\n",
    "gdb.fit(X_train, y_train)\n",
    "gdb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdb_model = gdb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdb_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
