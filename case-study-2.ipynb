{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_diabetes\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from regression_tools.plotting_tools import (\n",
    "    plot_univariate_smooth,\n",
    "    bootstrap_train,\n",
    "    display_coef,\n",
    "    plot_bootstrap_coefs,\n",
    "    plot_partial_depenence,\n",
    "    plot_partial_dependences,\n",
    "    predicteds_vs_actuals)\n",
    "\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'data/Train.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9cedd9f9c910>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# Read in columns we want\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/Train.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"saledate\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"YearMade\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'fiProductClassDesc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/test.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"saledate\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"YearMade\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'fiProductClassDesc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas/_libs/parsers.c:4209)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas/_libs/parsers.c:8873)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'data/Train.csv' does not exist"
     ]
    }
   ],
   "source": [
    "def create_machine_type_feature(df):\n",
    "    temp = pd.DataFrame(df['fiProductClassDesc'].str.split('-',1).tolist(),columns = ['MachineType','MachineSubType'])\n",
    "    df['MachineType'] = temp['MachineType']\n",
    "    df = df.drop(['fiProductClassDesc'], axis=1)\n",
    "    df = pd.concat([df, pd.get_dummies(df['MachineType'])], axis=1)\n",
    "    df = df.drop(['MachineType'], axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_age_in_years_feature(df):\n",
    "    '''\n",
    "    Creates 'AgeInYears' column.\n",
    "    Drops 'saledate' and 'YearMade' columns.\n",
    "    Returns resulting data frame.\n",
    "    '''\n",
    "    # Create column: 'AgeInYears' = 'saledate' - 'YearMade'\n",
    "    df['AgeInYears'] = pd.DatetimeIndex(df['saledate']).year - df['YearMade']\n",
    "    # Drop columns 'saledate' and 'YearMade'\n",
    "    df = df.drop(['saledate', 'YearMade'], axis=1)\n",
    "    # return df\n",
    "    return df\n",
    "\n",
    "\n",
    "def standardize_X(X_train, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    # Use X_train to compute mean and standard deviation\n",
    "    scaler.fit(X_train)\n",
    "    # Standardize X_train\n",
    "    X_train_standardized = scaler.transform(X_train)\n",
    "    # Standardize X_test\n",
    "    X_test_standardized = scaler.transform(X_test)\n",
    "    return X_train_standardized, X_test_standardized\n",
    "\n",
    "\n",
    "def preprocess(df_train, df_test):\n",
    "    \n",
    "    # Drop rows with 'YearMade' of 1000\n",
    "    df_train.drop(df_train[df_train['YearMade']==1000].index,inplace=True)\n",
    "#     df_test.drop(df_test[df_test['YearMade']==1000].index,inplace=True)\n",
    "    \n",
    "    df_train = create_machine_type_feature(df_train)\n",
    "    df_test = create_machine_type_feature(df_test)\n",
    "    \n",
    "    # Create 'AgeInYears' column. Drop 'saledate' and 'YearMade' columns.\n",
    "    df_train = create_age_in_years_feature(df_train)\n",
    "    df_test = create_age_in_years_feature(df_test)\n",
    "    \n",
    "    X_train = df_train.as_matrix()\n",
    "    X_test = df_test.as_matrix()\n",
    "    \n",
    "    X_train, X_test = standardize_X(X_train, X_test)\n",
    "    \n",
    "    return X_train, X_test\n",
    "    \n",
    "    \n",
    "# Read in columns we want\n",
    "df_train = pd.read_csv('data/Train.csv',usecols=[\"saledate\", \"YearMade\",'fiProductClassDesc'])\n",
    "df_test = pd.read_csv('data/test.csv',usecols=[\"saledate\", \"YearMade\",'fiProductClassDesc'])\n",
    "\n",
    "y_train = pd.read_csv('data/Train.csv',usecols=[\"SalePrice\",\"YearMade\"])\n",
    "# Drop rows with 'YearMade' of 1000\n",
    "y_train.drop(y_train[y_train['YearMade']==1000].index,inplace=True)\n",
    "y_train.drop(['YearMade'], axis=1,inplace=True)\n",
    "y_train = y_train.as_matrix()\n",
    "\n",
    "y_test = pd.read_csv('data/end_of_day/test_actual.csv',usecols=[\"SalePrice\"]).as_matrix()\n",
    "\n",
    "X_train, X_test = preprocess(df_train, df_test)\n",
    "\n",
    "# print('TRAIN X: ', X_train)\n",
    "# print('TEST X: ', X_test)\n",
    "# print('TRAIN y: ', y_train)\n",
    "# print('TEST y: ', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# quick fit\n",
    "model = Ridge(alpha=330)\n",
    "model.fit(X_train, y_train)\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "RMSE = np.sqrt(mean_squared_error(y_hat,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_univariate(df,cols,dep_val):\n",
    "    univariate_plot_names = cols\n",
    "    if len(univariate_plot_names)%2 ==0:\n",
    "        upn_len = int(len(univariate_plot_names)/2)\n",
    "    else:\n",
    "        upn_len = int(len(univariate_plot_names)/2+1)\n",
    "    fig, axs = plt.subplots(upn_len, 2, figsize=(14, 8))\n",
    "\n",
    "    for name, ax in zip(univariate_plot_names, axs.flatten()):\n",
    "        plot_univariate_smooth(ax,\n",
    "                               df[name].values.reshape(-1, 1).astype(np.float64),\n",
    "                               df[dep_val],\n",
    "                               bootstrap=100)\n",
    "        ax.set_title(name)\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.concat([pd.DataFrame(df_train), pd.DataFrame(y_train)], axis=1)\n",
    "full_df.drop(['MachineType'], axis=1, inplace=True)\n",
    "cols = [x for x in full_df.columns]\n",
    "dep_val = cols[-1]\n",
    "plot_univariate(full_df,cols[:-1],dep_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmsle(actual, predictions):\n",
    "    log_diff = np.log(predictions+1) - np.log(actual+1)\n",
    "    return np.sqrt(np.mean(log_diff**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_val(X, y, model, n_folds, errortype='RMSE', random_seed=154):\n",
    "    \"\"\"Estimate the in- and out-of-sample error of a model using cross\n",
    "    validation.\n",
    "    \n",
    "    Requirements\n",
    "    ----------\n",
    "    class XyScaler\n",
    "    function rmsle\n",
    " \n",
    "    Parameters\n",
    "    ----------\n",
    " \n",
    "    X: np.array\n",
    "      Matrix of predictors, standardized\n",
    " \n",
    "    y: np.array\n",
    "      Target array, standardized\n",
    " \n",
    "    model: sklearn model object.\n",
    "      The estimator to fit.  Must have fit and predict methods.\n",
    " \n",
    "    n_folds: int\n",
    "      The number of folds in the cross validation.\n",
    "    \n",
    "    errortype: string\n",
    "      either 'RMSE' or 'RMSLE'\n",
    " \n",
    "    random_seed: int\n",
    "      A seed for the random number generator, for repeatability.\n",
    " \n",
    "    Returns\n",
    "    -------\n",
    " \n",
    "    errors, cfs_best: tuple of arrays\n",
    "      errors = (train errors, test errors) for each fold of cross-validation\n",
    "      cfs-best = coefficients selected from minimum test error\n",
    "    \"\"\"\n",
    "    kf = KFold(n_folds)\n",
    "    errorlist = []\n",
    "    cfs = []\n",
    "    for k, (train_index,test_index) in enumerate(kf.split(X)):\n",
    "        # define variables\n",
    "        X_train = X[train_index]\n",
    "        y_train = y[train_index]\n",
    "        X_test = X[test_index]\n",
    "        y_test = y[test_index]\n",
    "        # fit model\n",
    "        model.fit(X_train,y_train)\n",
    "        y_hat_train = model.predict(X_train)\n",
    "        y_hat_test = model.predict(X_test) \n",
    "        # evaluate model\n",
    "        if errortype == 'RMSE':\n",
    "            rmse_train = np.sqrt(mean_squared_error(y_hat_train,y_train))\n",
    "            rmse_test = np.sqrt(mean_squared_error(y_hat_test,y_test))\n",
    "            errorlist.append((rmse_train, rmse_test)) # tuple output\n",
    "        elif errortype == 'RMSLE':\n",
    "            rmsle_train = rmsle(y_train, y_hat_train)\n",
    "            rmsle_test = rmsle(y_test, y_hat_test)\n",
    "            errorlist.append((rmsle_train, rmsle_test)) # tuple output\n",
    "        # store coefficients\n",
    "        cfs.append (model.coef_)\n",
    "    # select best coefficients \n",
    "    errors = np.asarray(errorlist)\n",
    "    idx_min_test_error = errors[:,1].argmin()   \n",
    "    cfs_best = cfs[idx_min_test_error]\n",
    "    \n",
    "    return(errors, cfs_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_at_various_alphas(X, y, model, alphas, n_folds=10, errortype='RMSE', **kwargs):\n",
    "    \"\"\"Train a regularized regression model using cross validation at various\n",
    "    values of alpha.\n",
    "    \n",
    "    requirements\n",
    "    ----------\n",
    "    class XyScaler\n",
    "    function rmsle\n",
    "    function cross_val\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    " \n",
    "    X: np.array\n",
    "      Matrix of predictors, standardized\n",
    " \n",
    "    y: np.array\n",
    "      Target array, standardized\n",
    " \n",
    "    model: name of sklearn model class\n",
    "      A class in sklearn that can be used to create a regularized regression\n",
    "      object.  Options are `Ridge` and `Lasso`.\n",
    " \n",
    "    alphas: numpy array\n",
    "      An array of regularization parameters.\n",
    " \n",
    "    n_folds: int\n",
    "      Number of cross validation folds.\n",
    "    \n",
    "    errortype: string\n",
    "      either 'RMSE' or 'RMSLE'\n",
    " \n",
    "    Returns\n",
    "    -------\n",
    " \n",
    "    cv_errors_train, cv_errors_test: tuple of DataFrame\n",
    "      DataFrames containing the training and testing errors for each value of\n",
    "      alpha and each cross validation fold.  Each row represents a CV fold, and\n",
    "      each column a value of alpha.\n",
    "      \n",
    "      Dataframe containing coefficients for each parameter for each alpha\n",
    "    \"\"\"\n",
    "    cv_errors_train = pd.DataFrame(np.empty(shape=(n_folds, len(alphas))),\n",
    "                                     columns=alphas)\n",
    "    cv_errors_test = pd.DataFrame(np.empty(shape=(n_folds, len(alphas))),\n",
    "                                        columns=alphas)\n",
    "    coefs_df = pd.DataFrame(np.empty(shape=(n_folds, len(alphas))),\n",
    "                                        columns=alphas)\n",
    "    for idx, alpha in enumerate(alphas):\n",
    "        errors, coefs = cross_val(X, y, model(alpha), n_folds, errortype='RMSE', random_seed=154)\n",
    "        cv_errors_train.iloc[:,idx] = errors[:,0]\n",
    "        cv_errors_test.iloc[:,idx] = errors[:,1]\n",
    "        #coefs_df.iloc[:,idx] = coefs\n",
    "    return(cv_errors_train, cv_errors_test)#, coefs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_sub = X_train[:1000]\n",
    "y_sub = y_train[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Lasso(alpha=330)\n",
    "n_folds = 2\n",
    "errortype = 'RMSE'\n",
    "errors, coefs = cross_val(X_sub, y_sub, model, n_folds, errortype, random_seed=154)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_sub\n",
    "y = y_sub\n",
    "model = Lasso # must be 'Ridge' or 'Lasso'\n",
    "alphas = np.logspace(-1,5,30)\n",
    "n_folds=5\n",
    "errortype='RMSE'\n",
    "cv_errors_train, cv_errors_test = train_at_various_alphas(X, y, model, alphas, n_folds, errortype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs from alpha testing\n",
    "train_means = cv_errors_train.mean(axis=0)\n",
    "test_means = cv_errors_test.mean(axis=0)\n",
    "# calc min alpha\n",
    "min_idx = test_means.values.argmin()\n",
    "min_alpha = alphas[min_idx]\n",
    "print('min error = {}'.format(np.min(test_means)))\n",
    "print('alpha at min error = {}'.format(min_alpha))\n",
    "\n",
    "fig, axs = plt.subplots(1,1,figsize=(5,5));\n",
    "h1 = axs.plot(alphas,train_means,'b-')\n",
    "h2 = axs.plot(alphas,test_means,'k-')\n",
    "axs.set_xscale('log')\n",
    "axs.invert_xaxis()\n",
    "axs.set_xlabel('alpha')\n",
    "axs.set_ylabel('error')\n",
    "plt.axvline(min_alpha, linestyle='dashed')\n",
    "plt.legend(('train','test'));\n",
    "#axs.set_yscale('log');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot: coefficients vs lambda\n",
    "\n",
    "# fig, axs = plt.subplots(1,1,figsize=(6,6));\n",
    "# axs.set_xlabel('alpha')\n",
    "# axs.set_ylabel('coefficient')\n",
    "\n",
    "# for idx, a in enumerate(alphas):\n",
    "#     h1 = axs.scatter(alphas[idx],coefs_df[a][0])\n",
    "#     h2 = axs.scatter(alphas[idx],coefs_df[a][1])\n",
    "#     h3 = axs.scatter(alphas[idx],coefs_df[a][2])\n",
    "#     h4 = axs.scatter(alphas[idx],coefs_df[a][3])\n",
    "#     h5 = axs.scatter(alphas[idx],coefs_df[a][4])\n",
    "# plt.legend(('c1','c2','c3','c4','c5'));\n",
    "# axs.set_xscale('log');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def boot(X, y, size=10000):\n",
    "    index_list = np.arange(len(X))\n",
    "    coefs = []\n",
    "    for i in range(size):\n",
    "        idxs = np.array([np.random.choice(index_list) for v in X])\n",
    "        X_data = X[idxs]\n",
    "        y_data = y[idxs]\n",
    "        model = Ridge(alpha=.5)\n",
    "        model.fit(X_data,y_data)\n",
    "        coefs.append(model.coef_)\n",
    "    return coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_arrays(lol_cofs):\n",
    "    coef1 = []\n",
    "    idx = 0\n",
    "    for row in lol_cofs:\n",
    "        coef1.append(row[idx])\n",
    "    return coef1\n",
    "    plt.hist(make_arrays, normed=True, bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cof_boot = boot(X_test, y_test, size=50)\n",
    "array = make_arrays(cof_boot);\n",
    "plt.hist(array, normed=True, bins=30);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ideas\n",
    "# can use lasso to pick params:\n",
    "# e.g. lasso = Lasso(alpha=a), lasso.fit(X,y), newX = [x for x in lasso.coefs_ where x > 0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
